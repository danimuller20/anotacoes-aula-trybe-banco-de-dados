# Testes de Integra√ß√£o (Integration Tests)

Aprendemos anteriormente sobre testes unit√°rios e como podemos testar cada unidade do nosso c√≥digo de maneira individual. Por exemplo, ao utilizarmos o padr√£o MSC podemos definir cada camada como sendo uma unidade:

<img src="images/msc.png"/>

_Arquitetura MSC_

Dessa forma, podemos testar cada camada, ou seja, cada unidade de maneira separada, isolando uma parte da outra e escrevendo testes individuais para cada uma:

<img src="images/unit-tests.png"/>

_Testes Unit√°rios_

Os testes de integra√ß√£o, ou integration tests , servem para verificar se a comunica√ß√£o entre os componentes de um sistema est√£o ocorrendo conforme o esperado.

Diferente dos testes unit√°rios, onde isolamos cada unidade como fizemos com cada camada do MSC, nos testes de integra√ß√£o o comportamento dever√° ser testado com a integra√ß√£o entre todas as unidades.

Ambos os tipos de testes s√£o importantes, por√©m, cada um tem um objetivo diferente.

Da mesma forma como definir uma unidade √© subjetivo, n√£o existe um n√≠vel de granularidade espec√≠fico de integra√ß√£o para ser testada, sendo poss√≠vel adaptar esse conceito de acordo com os objetivos desejados.

Nossa integra√ß√£o partir√° do recebimento do objeto da requisi√ß√£o ( request ), seguindo com o controlador ( controller ), o servi√ßo ( service ) e terminando no modelo ( model ). Iremos apenas isolar a comunica√ß√£o do model com o Banco de dados para evitarmos opera√ß√µes de IO. Podemos representar isso da seguinte maneira:

<img src="images/integration-tests.png"/>

_Testes de Integra√ß√£o_

# Contratos

Agora que j√° sabemos o n√≠vel de integra√ß√£o que iremos testar, ou seja, quais partes ser√£o cobertas pelos nossos testes, precisamos saber **o que exatamente queremos testar e de qual forma**.

Sempre quando consumimos ou fornecemos um servi√ßo, como por exemplo uma API REST, precisamos ter os comportamentos pr√© definidos. Esses comportamentos s√£o definidos de acordo com as regras de entrada e sa√≠da de dados da API.

Por exemplo, ao chamar um endpoint `GET /users/:userId` passamos um ID de usu√°rio e esperamos receber os dados referentes aquele usu√°rio com um c√≥digo `http 200 - OK`. Caso o usu√°rio n√£o seja encontrado, esperamos receber um status `http 404 - Not Found`, por exemplo.

Perceba que temos diversos padr√µes definidos e comportamentos esperados. Dessa forma, podemos testar exatamente se esses comportamentos est√£o sendo cumpridos por nossas API's, retornando uma resposta compat√≠vel com o cen√°rio.

Em testes, esse conceito √© chamado de contratos . Por exemplo, ao se alugar um im√≥vel, √© necess√°rio assinar um contrato onde est√° definido tudo aquilo que foi combinado entre as partes. Nos testes de contratos de API, a ideia √© bem semelhante, o contrato define aquilo que foi previamente acordado, ou seja, como a API dever√° se comportar em um determinado cen√°rio.

Para ficar ainda mais n√≠tido, vamos utilizar novamente o endpoint `GET /users/:userId`. Podemos dizer que o contrato dele √©, quando a pessoa usu√°ria existe, retornar a seguinte resposta:

* C√≥digo `HTTP: 200 - OK`;
* Body:

```json
{
    "id": "123",
    "name": "jane",
    "fullName": "Jane Doe",
    "email": "janedoe@trybemail.com"
}
```

Esse conceito trabalha muito bem junto com os testes de integra√ß√£o, pois podemos testar se cada contrato est√° sendo cumprido ap√≥s o processamento de todas as camadas.

# Escrevendo testes

### Baixando o reposit√≥rio base
[Reposit√≥rio](https://github.com/tryber/nodejs-jwt-base-project/tree/block-28-3)

### Preparando o ambiente

Antes de mais nada, devemos fazer a instala√ß√£o dos pacotes que j√° conhecemos anteriormente, para utilizaremos em ambiente de desenvolvimento, nos testes:

```sh
npm i -D mocha chai sinon
```

Aqui, tamb√©m √© necess√°rio a inicializa√ß√£o de um script de testes no `package.json`:
```json
...
"scripts": {
    ...
    "test": "mocha ./tests/**/*$NAME*.test.js --exit",
},
...
```

### Escrevendo um teste base

Agora vamos iniciar escrevendo testes para a rota de cria√ß√£o de usu√°rios.

Conforme definido, ao criar um usu√°rio com sucesso o endpoint dever√° responder:

* com o status `http 201 - OK`;
* com um objeto JSON, contendo a propriedade message com o valor `"Novo usu√°rio criado com sucesso"`.

Essa defini√ß√£o √© o contrato da nossa API. Podemos transform√°-lo em teste convertendo-o para asser√ß√µes/afirma√ß√µes, igual j√° fizemos anteriormente com o `mocha` e o `chai`:

_tests/createUsers.test.js_
```js
const chai = require('chai');

const { expect } = chai;

describe('POST /api/users', () => {
    describe('quando √© criado com sucesso', () => {
        let response = {};

        it('retorna o c√≥digo de status 201', () => {
            expect(response).to.have.status(201);
        });

        it('retorna um objeto', () => {
            expect(response.body).to.be.a('object');
        });

        it('o objeto possui a propriedade "message"', () => {
            expect(response.body).to.have.property('message');
        });

        it('a propriedade "message" possui o texto "Novo usu√°rio criado com sucesso"',
            () => {
                expect(response.body.message)
                    .to.be.equal('Novo usu√°rio criado com sucesso');
            });
    });
});
```
Agora que temos nosso contrato expresso em c√≥digo precisamos validar se nossa aplica√ß√£o est√° obedecendo aquilo que est√° definido nele.

### Testando nossa API

Iremos testar toda nossa API de maneira integrada, ou seja, queremos testar que dado um valor de entrada, o mesmo ser√° processado pelas diversas partes da API, ent√£o, nos dar um retorno conforme estabelecido pelo nosso "contrato". Diferente de como fizemos antes testando cada unidade da API com os testes unit√°rios por camada.

Para nos ajudar com esse desafio, utilizaremos o [plugin Chai HTTP](https://www.chaijs.com/plugins/chai-http/) com esse plugin poderemos simular uma request a nossa API.

Primeiro precisamos instalar esse novo pacote, para isso, execute:
```sh
npm install -D chai-http
```

E ent√£o no nosso teste iremos adicionar o seguinte trecho, adicionando o plugin a inst√¢ncia do chai:
```js
// const chai = require('chai');
const chaiHttp = require('chai-http');

chai.use(chaiHttp);

// const { expect } = chai

// ...
```

Adicionado o plugin ao chai, poderemos consumir nosso server em express atrav√©s dele, sem que haja a necessidade de subirmos a api manualmente. Para isso basta importarmos nossa api e ent√£o passamos ela como par√¢metro ao m√©todo request do chai.

Nesse caso, uma boa pr√°tica para a arquitetura da API, √© fazer a separa√ß√£o do conjunto da defini√ß√£o das rotas e regras de middlewares (Em um arquivo app.js , por exemplo. Que vai ser consumido pelo chaiHttp ) , do servidor propriamente dito, que consome essas regras (Esse continuaria em server.js , para utilizarmos em contextos de n√£o-teste):

```js
// ./src/api/app.js
const express = require('express');
const bodyParser = require('body-parser');
const routes = require('./routes');

const app = express();

app.use(bodyParser.urlencoded({ extended: false }));
app.use(bodyParser.json());

const apiRoutes = express.Router();
apiRoutes.get('/api/posts', routes.getPosts);
apiRoutes.post('/api/users', routes.createUsers);
apiRoutes.post('/api/login', routes.login);

app.use(apiRoutes);

/*
    Detalhe para a exporta√ß√£o do `app`, j√° que
    precisaremos dele nos testes com `chaiHttp`
*/
module.exports = app;
```

```js
// ./src/api/server.js
const port = process.env.PORT || 8080;
const app = require('./app');

app.listen(port);
console.log('conectado na porta ' + port);
```

Ap√≥s essa separa√ß√£o, voltando em `createUsers.test.js`, podemos testar nossos end-points utilizando a refer√™ncia deles contida em `./src/api/app.js`:

```js
// const chai = require('chai');
// const chaiHttp = require('chai-http');

const server = require('../src/api/app');

// chai.use(chaiHttp);

// const { expect } = chai;

// describe('POST /api/users', () => {
//     describe('quando √© criado com sucesso', () => {
//        let response;

        before(async () => {
            response = await chai.request(server);
        });

        /*
            Veremos adiante o exemplo completo üòâ
        */
//    });
//});
```
Ap√≥s chamarmos o m√©todo request passando o nosso server, podemos chamar diretamente nossos end-points, simulando chamadas HTTP.

Vejamos alguns exemplos disso:
```js
/*
    Podemos chamar um `GET` que deve consumir nossa api,
    sem que pra isso precisemos subir ela manualmente
*/
const response = await chai.request(server)
  .get('/exemplo');

/*
    Da mesma forma, podemos chamar um `POST` passando um
    `body` e/ou um `header`, por exemplo:
*/
const response = await chai.request(server)
  .get('/favorite-foods')
  .set('X-API-Key', 'foobar')
  .send({
      name: 'jane',
      favoriteFood: 'pizza'
  });
```

Dessa forma, o plugin nos ajudar√° a consumir nossa API em nossos testes de maneira muito simples, veja como ficar√° nosso teste ap√≥s o refactor completo:
```js
const chai = require('chai');
const chaiHttp = require('chai-http');

const server = require('../src/api/app');

chai.use(chaiHttp);

const { expect } = chai;

describe('POST /api/users', () => {
    describe('quando √© criado com sucesso', () => {
        let response;

        before(async () => {
            response = await chai.request(server)
                .post('/api/users')
                .send({
                    username: 'jane',
                    password: 'senha123'
                });
        });

        it('retorna o c√≥digo de status 201', () => {
            /*
                Perceba que aqui temos uma asser√ß√£o
                espec√≠fica para o status da `response` üò¨
            */
            expect(response).to.have.status(201);
        });

        it('retorna um objeto', () => {
            expect(response.body).to.be.a('object');
        });

        it('o objeto possui a propriedade "message"', () => {
            expect(response.body).to.have.property('message');
        });

        it('a propriedade "message" possui o texto "Novo usu√°rio criado com sucesso"',
            () => {
                expect(response.body.message)
                    .to.be.equal('Novo usu√°rio criado com sucesso');
            }
        );
    });
});
```
Antes de executarmos nossos testes, precisamos fazer mais um ajuste. Apesar de estarmos fazendo testes de integra√ß√£o, lembre-se que s√≥ queremos testar at√© nosso model , sem deixar que nossa aplica√ß√£o de fato v√° at√© o banco de dados, isolando o IO.

Para isso, utilizaremos novamente a estrat√©gia de utilizar uma inst√¢ncia do nosso banco de dados em mem√≥ria.

Nosso teste ficar√° assim:
```js
// const chai = require('chai');
const sinon = require('sinon');
// const chaiHttp = require('chai-http');

// const server = require('../src/api/app');

const { MongoClient } = require('mongodb');
const { MongoMemoryServer } = require('mongodb-memory-server');

// chai.use(chaiHttp);

// const { expect } = chai;

// describe('POST /api/users', () => {
//    describe('quando √© criado com sucesso', () => {
//        let response;
        const DBServer = new MongoMemoryServer();

//        before(async () => {
            const URLMock = await DBServer.getUri();
            const connectionMock = await MongoClient.connect(URLMock,
                { useNewUrlParser: true, useUnifiedTopology: true }
            );

            sinon.stub(MongoClient, 'connect')
                .resolves(connectionMock);

//            response = await chai.request(server)
//                .post('/api/users')
//                .send({
//                    username: 'jane',
//                    password: 'senha123'
//                });
//        });

        after(async () => {
            MongoClient.connect.restore();
            await DBServer.stop();
        });

//        it('retorna o c√≥digo de status 201', () => {
//            expect(response).to.have.status(201);
//        });

//        it('retorna um objeto', () => {
//            expect(response.body).to.be.a('object');
//        });

//        it('o objeto possui a propriedade "message"', () => {
//            expect(response.body).to.have.property('message');
//        });

//        it('a propriedade "message" possui o texto "Novo usu√°rio criado com sucesso"',
//              () => {
//                  expect(response.body.message)
//                      .to.be.equal('Novo usu√°rio criado com sucesso');
//              }
//        );
//    });
//});
```
E ent√£o podemos rodar nossos testes e, se nossa API estiver respeitando o contrato definido, teremos sucesso:

# Pensando testes para outros contextos
Como e qual teste preciso fazer? Pode n√£o parecer em um primeiro momento, mas como dito anteriormente, a testagem de sistemas complexos fica muito mais simples se pensarmos nos contratos que as situa√ß√µes exigem.

Uma outra forma de medir o n√≠vel entre escopo e intera√ß√£o na idealiza√ß√£o de um teste, √© buscar uma especificidade para que possamos transforma-lo em requisito. Nesse sentido, considere a seguinte pergunta:

**Se precisasse fazer o teste manualmente, qual seria o meu processo/ "teste de mesa"?**

Antes de continuar , experimente fazer esse exerc√≠cio individualmente, pensando o uso do JWT em uma API, em um contrato onde caso se tenha um login v√°lido, deva ser poss√≠vel trazer dados de posts (com status 200 - OK ).

Dependendo da resposta, podemos identificar os tipos de teste que precisaremos fazer:

```
## Exemplo de resposta nesse cen√°rio

Utilizaria o `postman`, onde:
   - Faria um login v√°lido na rota `POST /api/login` pra conseguir um `token`;
   - Aguardaria um status `200 - OK`, acompanhado de um JSON com o `token`;
   - Testaria a rota `GET /api/posts`, passando esse `token` no `header`:
     `authorization`;
   - Aguardaria um status `200 - OK`, acompanhado de um JSON com os `posts`.
```

Agora vamos identificar aqui aquilo que poderia ser um teste unit√°rio e aquilo que caracteriza um teste de integra√ß√£o:

```
## Analisando linha a linha
 Utilizaria o `postman`, onde:
<!--
    Aqui j√° notamos que o teste requer uma estrutura que depende de um servidor
    rodando. Esse teste, por tanto, leva em considera√ß√£o a `integra√ß√£o` de outros
    elementos, como a defini√ß√£o de um server, rotas e `controllers`;
-->
 Faria um login v√°lido na rota `POST /api/login`* pra conseguir um `token`**
<!--
    [*] Se estiv√©ssemos testando isoladamente um `model` que, ao receber os
    par√¢metros de email e password, pode se comportar de uma forma ou outra,
    esse poderia ser um `teste unit√°rio`;

    [**] Se estiv√©ssemos testando isoladamente o `service` que gera nosso
    `token`, ou seja, se estamos testando a capacidade de trabalhar com uma
    fun√ß√£o (ou `middleware`) que utiliza internamente o m√©todo `.sign()` do `jwt`
    (que por sua vez, n√£o precisa de um teste unit√°rio por ser uma biblioteca
    j√° testada), para encriptar dados aleat√≥rios ou 'mocks', esse poderia ser um
    `teste unit√°rio`.

    Se estamos no entanto, esperando que com base em um conjunto de dados v√°lidos,
    recebamos uma informa√ß√£o espec√≠fica (atrav√©s do consumo de uma api), esse √©,
    muito provavelmente, um `teste de integra√ß√£o`. Isso, porque esse teste precisa
    que v√°rios componentes da sua api estejam funcionando corretamente: `server`,
    `controller`, `service` e `model`.
-->
 Aguardaria um status `200 - OK`, acompanhado de um JSON com o `token`;
<!--
    Se estivermos testando isoladamente um `controller`, podemos assumir que esse
    trar√° um resultado ou outro, o que poderia ser um `teste unit√°rio`.

    Aqui, por√©m, esse comportamento pressup√µe uma a√ß√£o anterior, ou seja, ele √©
    disparado uma vez que a pessoa usu√°ria aciona o login. Sendo parte de um
    `teste de integra√ß√£o`, pois pressup√µe a etapa anterior e suas depend√™ncias.
-->
 Testaria a rota `GET /api/posts`, passando esse `token` no `header`:
 `authorization`;
<!--
    Como no item n¬∫2, poder√≠amos separar testes individuais para cada compet√™ncia
    nessa pipeline do express, ou seja, poder√≠amos ter `testes unit√°rios` para,
    por exemplo:
        - Middleware: `auth`, que validaria tokens;
        - Service: `getUser`, que validaria emails e senhas;
        - Model: `findUser`, onde trar√≠amos dados de pessoas usu√°rias no banco;
        - Service: `getAllPosts`, onde testar√≠amos alguma valida√ß√£o ou regra;
        - Model: `findPosts`, onde trar√≠amos dados de posts do banco;
        - Controller: `getPosts`, testando dados de retorno;

    Pensando o todo, esse teste depende dos demais, pois depende do `token` para
    funcionar corretamente. Aqui novamente, sendo parte de um `teste de
    integra√ß√£o`.
-->
 Aguardaria um status `200 - OK`, acompanhado de um JSON com os `posts`.
<!--
    Caso aqui n√£o estejamos testando um `controller`, ent√£o esse passo s√≥ faria
    sentido como uma asser√ß√£o/afirma√ß√£o ao final de um `teste de integra√ß√£o`.
-->
```

# Cobertura de testes
Uma forma de acompanhar o qu√£o bem estamos conseguindo exercitar a testagem do nosso sistema pode ser feita atrav√©s de relat√≥rios de cobertura . Boa parte das suites de teste das linguagens de programa√ß√£o possui uma forma de gerar um relat√≥rio desse tipo, no caso do NodeJS , conseguimos gerar esses relat√≥rios, tanto para os testes feitos no jest quanto no mocha (utilizando uma ferramenta chamada [nyc](https://github.com/istanbuljs/nyc)).

Esses relat√≥rios checam, se para um escopo de arquivos definidos (aqui podemos pensar o conte√∫do da nossa aplica√ß√£o, excluindo bibliotecas e arquivos de configura√ß√£o), os seus testes s√£o capazes de rodar todas as linhas dos arquivos relacionados , o que gera uma porcentagem total de cobertura para aquele escopo.

### Crit√©rios relevantes

De forma geral (tamb√©m para outras linguagens de programa√ß√£o), suites de testes geram relat√≥rios de cobertura segundo alguns [crit√©rios b√°sicos](https://en.wikipedia.org/wiki/Code_coverage#Basic_coverage_criteria), os mais relevantes para nosso contexto s√£o:

* **Cobertura de Fun√ß√µes** / Function Coverage: Cada fun√ß√£o/sub-rotina do script foi acionado/chamado?

* **Cobertura de Afirma√ß√µes** / Statement Coverage : Cada afirma√ß√£o/defini√ß√£o/comando do script foi executado?

* **Cobertura de Ramifica√ß√µes** / Branch Coverage : Cada situa√ß√£o de ramifica√ß√£o do c√≥digo (aqui podemos assumir um script condicional, como um `if { /*situa√ß√£o A*/ } else { /*situa√ß√£o B*/ }`) foi executada?

No nosso contexto, ambas ferramentas ( jest e nyc ) v√£o utilizar relat√≥rios do [Instanbul](https://istanbul.js.org/), por tanto em uma situa√ß√£o de exemplo, um relat√≥rio gerado em uma das nossas ferramentas, deve retornar uma tabela semelhante a essa:

<img src="images/coverage_table_example.png"/>

_Exemplo de um relat√≥rio de cobertura com `jest`/`nyc`_

* File (Arquivo): Retorna a estrutura do escopo analisado, cada linha √© referente a pasta ou arquivo espec√≠fico, no nosso caso, a cobertura esta analisando todos arquivos *.js contidos em ./src , que fica na raiz do projeto;

* Stmts (Statements/Afirma√ß√µes): Retorna os percentuais da cobertura de afirma√ß√µes executadas que citamos anteriormente, no nosso caso, √© poss√≠vel assumir que o arquivo middlewares/invert.middleware.js n√£o executou todas as suas defini√ß√µes/afirma√ß√µes . Note ainda, que em Uncovered Line #s (Linhas n√£o-cobertas) , o relat√≥rio identifica quais as linhas do arquivo n√£o foram executadas, no nosso caso, as linhas de 4 a 6 n√£o foram executadas em nenhum momento quando esse arquivo foi referenciado nos nossos testes (via require() , ou via par√¢metro de configura√ß√£o, o que veremos mais a frente);

* Branch (Ramo): Retorna o percentual de situa√ß√µes de ramifica√ß√£o cobertos . Se observarmos no arquivo logger.js , existe um percentual de 50% de situa√ß√µes n√£o-cobertas (ou seja, situa√ß√µes que n√£o foram testadas em nenhum momento), o relat√≥rio ainda aponta a linha 13 como a linha n√£o-coberta, aqui podemos assumir que essa linha faz parte do resultado de um script condicional (como um if{}else ). Se no arquivo n√£o houverem situa√ß√µes de ramifica√ß√£o, o retorno √© 100%.

Detalhe , o relat√≥rio vai considerar uma branch , mesmo que n√£o haja nenhuma situa√ß√£o de else para ela, ex:
```js
const debug = true;

module.exports = (req, res, next) => {
  if(debug){
    res.on('finish', () => {
      console.log({
        method: req.method,
        endPoint: req.originalUrl,
        status: res.statusCode
      })
    });
  }
  /*
    No caso desse `if`, n√£o existe cobertura pra uma situa√ß√£o onde `debug`
    √© falso, ent√£o, ainda que um teste cubra 100% desse c√≥digo, o retorno
    em `% Branch` para esse arquivo, ser√° 50%;
  */

  next();
}
```

* Funcs (Functions/Fun√ß√µes): Retorna o percentual de fun√ß√µes executadas nos arquivos. Em middlewares/invert.middleware.js e server.js , podemos assumir que nenhuma das fun√ß√µes desses arquivos foi executada nos nossos testes. Em server.js , ainda, √© poss√≠vel identificar que o arquivo n√£o foi nem mesmo referenciado nos testes, j√° que nenhuma defini√ß√£o do mesmo foi executada (Coluna % Stmts );

* Lines (Linhas): Retorna o percentual de linhas executadas nos arquivos, no caso de All files , esse valor representa o total de cobertura da sua suite de testes , que no nosso caso representa 81,08% de cobertura total, dado os problemas apresentados.

### Como gerar uma cobertura de testes no meu ambiente?

Como visto acima, tanto no o jest quanto no nyc , √© poss√≠vel gerar um relat√≥rio de cobertura padr√£o. E a depender da forma da utiliza√ß√£o de cada um, √© poss√≠vel ainda trazer [relat√≥rios em diferentes formatos](https://istanbul.js.org/docs/advanced/alternative-reporters/) (como em `html`, por exemplo).

A princ√≠pio, vamos passar pelos comandos b√°sicos para execu√ß√£o e a descri√ß√£o de cada um, ap√≥s isso, passaremos pela API de exemplo que utilizamos hoje, gerando um relat√≥rio de cobertura utilizando o nyc:

### Comando b√°sico

No jest, utilizamos o par√¢metro `--coverage` (como em `jest --coverage`), assim, podemos pensar a seguinte configura√ß√£o de scripts no `package.json`:

```json
...
"scripts": {
    ...
    "test": "jest ./tests",
    "test:coverage": "npm test -- --coverage",
    ...
},
...
```

Dessa forma, conseguimos ter um script pr√≥prio para gerar esse relat√≥rio, que rodamos com `npm run test:coverage`.

No mocha , antes, temos que instalar a biblioteca nyc (que √© a cli - interface de linha de comando, do Instanbul):
```sh
npm i -D nyc
```

Ap√≥s isso, a utiliza√ß√£o tamb√©m √© bastante simples, utilizaremos o nyc , passando como par√¢metro o comando que utilizaremos para os testes em mocha , exemplo: `nyc mocha ./tests --recursive`. Dessa forma, conseguimos fazer uma configura√ß√£o de scripts similar ao do jest:

```json
...
"scripts": {
    ...
    "test": "mocha ./tests --recursive",
    "test:coverage": "nyc npm test",
    ...
},
...
```

### Personalizando o escopo de cobertura

Por padr√£o, os reporters v√£o fazer a cobertura dos arquivos que s√£o referenciados nos seus testes. Para trazer a porcentagem de cobertura dentro de um escopo fixo voc√™ pode:

No jest , de duas formas:

* Utilizando um [arquivo de configura√ß√£o](https://jestjs.io/pt-BR/docs/configuration) `jest.config.js` (que deve ser referenciado via cli com o par√¢metro [--config=< seuArquivoDeConfig >](https://jestjs.io/pt-BR/docs/cli#--configpath)). Esse arquivo pode receber uma propriedade [collectCoverageFrom](https://jestjs.io/pt-BR/docs/configuration#collectcoveragefrom-array), contendo o padr√£o a ser respeitado;

* Utilizando o mesmo comando, via cli: `--collectCoverageFrom`, da seguinte forma:

```json
...
"scripts": {
    ...
    "test": "jest ./tests",
    "test:coverage": "npm test -- --coverage --collectCoverageFrom='src/**/*.js'",
    ...
},
...
```

No `nyc`, de duas formas:

* Utilizando um [arquivo de configura√ß√£o](https://github.com/istanbuljs/nyc#configuration-files) `nyc.config.js` na raiz do projeto. Esse arquivo pode receber uma propriedade include, contendo o padr√£o a ser respeitado;

* Utilizando o mesmo comando, via cli: `--include`, da seguinte forma:

```json
...
"scripts": {
    ...
    "test": "mocha ./tests --recursive",
    "test:coverage": "nyc --include='src/**/*.js' npm run test",
    ...
},
...
```

* √â poss√≠vel ainda, via cli, utilizar o par√¢metro `--all` para coletar a cobertura de todos os arquivos (mesmo os que n√£o tem refer√™ncia nos testes).

_Notem aqui, que estamos colocando nosso c√≥digo fonte dentro de uma pasta ./src , para que n√£o seja necess√°rio criar uma lista de exclus√£o de cobertura (para pasta node_modules ou a pr√≥pria pasta tests , por exemplo), nesse sentido, tamb√©m √© importante manter a pasta tests na raiz, pelo mesmo motivo;_

### Rodando um teste de cobertura no projeto atual

Seguindo os passos anteriores, basta adicionar um script no nosso package.json contendo o escopo de cobertura:

```json
...
"scripts": {
    ...
    "test": "mocha ./tests/**/*$NAME*.test.js --exit",
    "test:coverage": "nyc --include='src/**/*.js' npm run test",
    ...
},
...
```

Ap√≥s isso, basta rodar o comando npm run test:coverage;

<img src="images/coverage_jwt_base.png"/>

_Cobertura do projeto de exemplo `jwt-base`_

```js
```

```js
```

```js
```
